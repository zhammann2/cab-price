{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data from CSV\n",
    "pre_proccessed_data = pd.read_csv('CSV FILE NAME.csv')  # Replace with your CSV file name\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = pre_processed_data.drop(columns=['price']) # Assuming 'price' is the target variable\n",
    "y = pre_processed_data['price']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "linear_model = LinearRegression()\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit Models\n",
    "linear_model.fit(X_train, y_train)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model\n",
    "def evaluate_model(model, X, y, kf):\n",
    "  r2_scores = []\n",
    "  mse_scores = []\n",
    "  \n",
    "  for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "  \n",
    "  return r2_scores, mse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Linear Regression\n",
    "lr_r2_scores, lr_mse_scores = evaluate_model(linear_model, X, y, kf)\n",
    "\n",
    "# Evaluate Random Forest Regressor\n",
    "rf_r2_scores, rf_mse_scores = evaluate_model(random_forest_model, X, y, kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"R² Scores: {lr_r2_scores}\")\n",
    "print(f\"Mean R²: {sum(lr_r2_scores) / len(lr_r2_scores)}\")\n",
    "print(f\"MSE Scores: {lr_mse_scores}\")\n",
    "print(f\"Mean MSE: {sum(lr_mse_scores) / len(lr_mse_scores)}\")\n",
    "\n",
    "print(\"\\nRandom Forest Regressor:\")\n",
    "print(f\"R² Scores: {rf_r2_scores}\")\n",
    "print(f\"Mean R²: {sum(rf_r2_scores) / len(rf_r2_scores)}\")\n",
    "print(f\"MSE Scores: {rf_mse_scores}\")\n",
    "print(f\"Mean MSE: {sum(rf_mse_scores) / len(rf_mse_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of R² and MSE\n",
    "\n",
    "**R² (Coefficient of Determination):**  \n",
    "R² measures how well the model's predictions match the actual data. It represents the proportion of the variance in the dependent variable that is predictable from the independent variables.  \n",
    "- **Range:** 0 to 1 (sometimes negative if the model performs worse than a simple mean prediction).  \n",
    "- **Interpretation:** A higher R² indicates a better fit of the model to the data.  \n",
    "\n",
    "**MSE (Mean Squared Error):**  \n",
    "MSE measures the average squared difference between the predicted and actual values. It quantifies the error of the model's predictions.  \n",
    "- **Range:** 0 to ∞ (lower is better).  \n",
    "- **Interpretation:** A smaller MSE indicates that the model's predictions are closer to the actual values.  \n",
    "\n",
    "### Why We Use Them\n",
    "- **R²** helps us understand the proportion of variance explained by the model, providing a measure of goodness-of-fit.  \n",
    "- **MSE** gives a direct measure of prediction error, helping us evaluate how far off the predictions are on average.  \n",
    "\n",
    "By using both metrics, we gain a comprehensive understanding of the model's performance in terms of both accuracy and explanatory power."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
