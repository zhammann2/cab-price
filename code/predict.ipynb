{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data from CSV\n",
    "linear_regressor_data = pd.read_csv('../processed_data/linear_data.csv')\n",
    "random_forest_data = pd.read_csv('../processed_data/linear_data.csv')\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "lr_X = linear_regressor_data.drop(columns=['price']) # Assuming 'price' is the target variable\n",
    "lr_y = linear_regressor_data['price']\n",
    "\n",
    "rf_X = random_forest_data.drop(columns=['price']) # Assuming 'price' is the target variable\n",
    "rf_y = random_forest_data['price']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "lr_X_train, lr_X_test, lr_y_train, lr_y_test = train_test_split(lr_X, lr_y, test_size=0.2, random_state=42)\n",
    "rf_X_train, rf_X_test, rf_y_train, rf_y_test = train_test_split(lr_X, lr_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "linear_model = LinearRegression()\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit Models\n",
    "linear_model.fit(lr_X_train, lr_y_train)\n",
    "random_forest_model.fit(rf_X_train, rf_y_train)\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression on Test Data:\n",
      "Predictions: [12.7431303  11.42058298  5.98541763 ... 18.25645164  8.24065532\n",
      " 12.12793595]\n",
      "Avg Predictions: 16.5467784013855\n",
      "R²: 0.9284076244114665\n",
      "MSE: 6.241453558623612\n",
      "\n",
      "Random Forest Regressor on Test Data:\n",
      "Predictions: [ 7.76428725 10.7824511   7.54506381 ... 16.19674329  9.09728283\n",
      " 10.66570347]\n",
      "Avg Predictions: 16.541862340153997\n",
      "R²: 0.9698302209967633\n",
      "MSE: 2.630214083199093\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Linear Regression on test data\n",
    "lr_y_pred = linear_model.predict(lr_X_test)\n",
    "lr_test_r2 = r2_score(lr_y_test, lr_y_pred)\n",
    "lr_test_mse = mean_squared_error(lr_y_test, lr_y_pred)\n",
    "\n",
    "# Evaluate Random Forest Regressor on test data\n",
    "rf_y_pred = random_forest_model.predict(rf_X_test)\n",
    "rf_test_r2 = r2_score(rf_y_test, rf_y_pred)\n",
    "rf_test_mse = mean_squared_error(rf_y_test, rf_y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Linear Regression on Test Data:\")\n",
    "print(f\"Predictions: {lr_y_pred}\")\n",
    "print(f\"Avg Predictions: {lr_y_pred.mean()}\")\n",
    "print(f\"R²: {lr_test_r2}\")\n",
    "print(f\"MSE: {lr_test_mse}\")\n",
    "\n",
    "print(\"\\nRandom Forest Regressor on Test Data:\")\n",
    "print(f\"Predictions: {rf_y_pred}\")\n",
    "print(f\"Avg Predictions: {rf_y_pred.mean()}\")\n",
    "print(f\"R²: {rf_test_r2}\")\n",
    "print(f\"MSE: {rf_test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Fold cross-validation for Linear Regression\n",
    "lr_r2_scores = cross_val_score(linear_model, lr_X, lr_y, scoring='r2')\n",
    "lr_mse_scores = -cross_val_score(linear_model, lr_X, lr_y, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Fold cross-validation for Random Forest Regressor\n",
    "rf_r2_scores = cross_val_score(random_forest_model, rf_X, rf_y, cv=kf, scoring='r2')\n",
    "rf_mse_scores = -cross_val_score(random_forest_model, rf_X, rf_y, cv=kf, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R² Scores: [0.92807045 0.92908097 0.92748786 0.92885245 0.92796395]\n",
      "Mean R²: 0.9282911379560372\n",
      "MSE Scores: [6.31092157 6.14750265 6.34246457 6.14178321 6.23093449]\n",
      "Mean MSE: 6.234721297091413\n",
      "\n",
      "Random Forest Regressor:\n",
      "R² Scores: [0.96983177 0.96971116 0.96964991 0.9687842  0.9683056 ]\n",
      "Mean R²: 0.9692565277360965\n",
      "MSE Scores: [2.63007928 2.63242562 2.63194557 2.69928566 2.77118487]\n",
      "Mean MSE: 2.672984200502959\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"R² Scores: {lr_r2_scores}\")\n",
    "print(f\"Mean R²: {sum(lr_r2_scores) / len(lr_r2_scores)}\")\n",
    "print(f\"MSE Scores: {lr_mse_scores}\")\n",
    "print(f\"Mean MSE: {sum(lr_mse_scores) / len(lr_mse_scores)}\")\n",
    "\n",
    "print(\"\\nRandom Forest Regressor:\")\n",
    "print(f\"R² Scores: {rf_r2_scores}\")\n",
    "print(f\"Mean R²: {sum(rf_r2_scores) / len(rf_r2_scores)}\")\n",
    "print(f\"MSE Scores: {rf_mse_scores}\")\n",
    "print(f\"Mean MSE: {sum(rf_mse_scores) / len(rf_mse_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of R² and MSE\n",
    "\n",
    "**R² (Coefficient of Determination):**  \n",
    "R² measures how well the model's predictions match the observed data. It represents the proportion of the variance in the dependent variable that is explained by the independent variables.  \n",
    "- **Range:** 0 to 1 (sometimes negative if the model performs worse than a simple mean prediction).  \n",
    "- **Interpretation:** A higher R² indicates a better fit of the model to the data.  \n",
    "\n",
    "**MSE (Mean Squared Error):**  \n",
    "MSE measures the average squared difference between the predicted and actual values. It quantifies the error of the model's predictions.  \n",
    "- **Range:** 0 to ∞ (lower is better).  \n",
    "- **Interpretation:** A smaller MSE when compared to another model indicates that the model's predictions are closer to the actual values.  \n",
    "\n",
    "### Why We Use Them\n",
    "- **R²** helps us understand the proportion of variance explained by the model, providing a measure of goodness-of-fit.  \n",
    "- **MSE** gives a direct measure of prediction error, helping us evaluate how far off the predictions are on average.  \n",
    "\n",
    "By using both metrics, we gain a comprehensive understanding of the model's performance in terms of both accuracy and explanatory power.\n",
    "\n",
    "### Result Analysis\n",
    "\n",
    "**R² Results:**  \n",
    "Both models achieved strong R² scores, indicating a good fit to the data. However, the **Random Forest Regression model slightly outperformed the Linear Regression model**, suggesting it captures more of the variance in fare prices.  \n",
    "- **Linear Regression Mean R²:** 0.928  \n",
    "- **Random Forest Regression Mean R²:** 0.969  \n",
    "\n",
    "This indicates that while Linear Regression explains about 92.8% of the variance in fare prices, Random Forest explains approximately 96.9%, making it a better fit for this dataset.\n",
    "\n",
    "**MSE Results:**  \n",
    "When comparing prediction error, Random Forest also outperformed Linear Regression by a noticeable margin.  \n",
    "- **Linear Regression Mean MSE:** 6.235  \n",
    "- **Random Forest Regression Mean MSE:** 2.673  \n",
    "\n",
    "This shows that, on average, Random Forest's predictions are significantly closer to the actual fare prices, with an error reduction of roughly **57%** compared to Linear Regression. The lower MSE confirms that Random Forest provides more accurate predictions for this problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
